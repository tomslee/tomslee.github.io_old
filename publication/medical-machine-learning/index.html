<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.3.1">

  

  
  
  
  
  
    
    
    
  
  

  

  
  
  
    
  
  <meta name="description" content="Researchers from Harvard and MIT warn us about &ldquo;Adversarial attacks on medical machine learning&rdquo;, in which &ldquo;a small, carefully designed change in how inputs are presented to a system&hellip; completely alter its output, causing it to arrive at manifestly wrong conclusions.&rdquo; (Link) I think that&rsquo;s only half the story&hellip;

 Table of Contents  Adversarial attacks and workarounds in medical machine learning   
Adversarial attacks and workarounds in medical machine learning It&rsquo;s not like the Harvard/MIT article is purely about adversarial attacks.">

  
  <link rel="alternate" hreflang="en-us" href="https://tomslee.github.io/publication/medical-machine-learning/">

  


  

  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    

    

  

  
  

  
  
  
  <link rel="stylesheet" href="/css/academic.min.cd4a39569d1c33b7bd15c30b7962dc73.css">

  

  
  
  

  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://tomslee.github.io/publication/medical-machine-learning/">

  
  
  
  
    
    
  
  <meta property="twitter:card" content="summary">
  
  <meta property="twitter:site" content="@whimsley">
  <meta property="twitter:creator" content="@whimsley">
  
  <meta property="og:site_name" content="Tom Slee">
  <meta property="og:url" content="https://tomslee.github.io/publication/medical-machine-learning/">
  <meta property="og:title" content="Workarounds in decision support systems | Tom Slee">
  <meta property="og:description" content="Researchers from Harvard and MIT warn us about &ldquo;Adversarial attacks on medical machine learning&rdquo;, in which &ldquo;a small, carefully designed change in how inputs are presented to a system&hellip; completely alter its output, causing it to arrive at manifestly wrong conclusions.&rdquo; (Link) I think that&rsquo;s only half the story&hellip;

 Table of Contents  Adversarial attacks and workarounds in medical machine learning   
Adversarial attacks and workarounds in medical machine learning It&rsquo;s not like the Harvard/MIT article is purely about adversarial attacks."><meta property="og:image" content="https://tomslee.github.io/img/icon-192.png">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2019-08-02T15:58:08-04:00">
  <meta property="article:modified_time" content="2019-08-02T15:58:08-04:00">
  

  

<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.0.3/cookieconsent.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.0.3/cookieconsent.min.js"></script>
<script>
  window.addEventListener("load", function(){
    window.cookieconsent.initialise({
      "palette": {
        "popup": {
          "background": "#2962ff",
          "text": "#fff"
        },
        "button": {
          "background": "#fff",
          "text": "#2962ff"
        }
      },
      "theme": "classic",
      "content": {
        "message": "This website uses cookies to ensure you get the best experience on our website.",
        "dismiss": "Got it!",
        "link": "Learn more",
        "href": "https://cookies.insites.com"
      }
    })});
</script>



  





  <title>Workarounds in decision support systems | Tom Slee</title>

</head>


<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" role="textbox" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  
<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">Tom Slee</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav mr-auto">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#publications"><span>Essays</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts"><span>Blog</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>About</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

      
      </ul>
      <ul class="navbar-nav ml-auto">
      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        

      </ul>

    </div>
  </div>
</nav>


  <div class="pub" itemscope itemtype="http://schema.org/CreativeWork">

  












  

  
  
  
<div class="article-container pt-3">
  <h1 itemprop="name">Workarounds in decision support systems</h1>

  

  
    



<meta content="2019-08-02 15:58:08 -0400 EDT" itemprop="datePublished">
<meta content="2019-08-02 15:58:08 -0400 EDT" itemprop="dateModified">

<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    <time>August 2019</time>
  </span>
  

  

  

  
  

  
  

  
    
<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https://tomslee.github.io/publication/medical-machine-learning/&amp;text=Workarounds%20in%20decision%20support%20systems" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Workarounds%20in%20decision%20support%20systems&amp;body=https://tomslee.github.io/publication/medical-machine-learning/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
  </ul>
</div>


  

</div>

    














  
</div>



  <div class="article-container">

    

    

    

    <div class="space-below"></div>

    <div class="article-style">

<div class="ABSTRACT">
  <div></div>

<p><em>Researchers from Harvard and MIT warn us about &ldquo;Adversarial attacks on medical machine learning&rdquo;, in which &ldquo;a small, carefully designed change in how inputs are presented to a system&hellip; completely alter its output, causing it to arrive at manifestly wrong conclusions.&rdquo; (<a href="https://science.sciencemag.org/content/363/6433/1287" target="_blank">Link</a>) I think that&rsquo;s only half the story&hellip;</em></p>

<p></div></p>

<div class="ox-hugo-toc toc">
<div></div>

<div class="heading">Table of Contents</div>

<ul>
<li><a href="#adversarial-attacks-and-workarounds-in-medical-machine-learning">Adversarial attacks and workarounds in medical machine learning</a></li>
</ul>

<p></div>
<!--endtoc--></p>

<h2 id="adversarial-attacks-and-workarounds-in-medical-machine-learning">Adversarial attacks and workarounds in medical machine learning</h2>

<p>It&rsquo;s not like the Harvard/MIT article is <em>purely</em> about adversarial attacks. Early on the authors point out that the American medical claims approval process is plagued by many competing financial interests, &ldquo;providers [i.e. doctors and hospitals] seeking to maximize and payers [insurance companies] seeking to minimize reinbursement.&rdquo;</p>

<p>But the remainder of the paper focuses almost exclusively on the problem of adversarial attacks by healthcare providers. Deep learning algorithms may be uncannily accurate over a well-defined data set, but they are also fragile if a sample steps in an unexpected direction, and this fragility leaves them open to &ldquo;attack&rdquo;. Most blatantly, the authors show, doctors could modify medical images to change the diagnosis, even as the image appears unchanged to the human eye. Then there are grey areas, like rotations of an image, or a careful choice of words in notes, that pushes the system to give unexpected results. How should the medical system handle a techique that seems so accurate and yet so easily misled?</p>

<p>Adversarial attacks are &ldquo;inputs to a machine learning model that are intentionally crafted to force the model to make a mistake&rdquo;: that is, you take an input that the model classifies correctly and you tweak it so that it is classified incorrectly. <em>Workarounds</em> are the opposite of adversarial attacks: inputs that are intentionally crafted to force the model to <em>correct</em> a mistake. That is, you take an input that is incorrectly classified by the model and tweak it so that it is correctly classified.</p>

<p>Even the best machine learning systems are, after all, statistical engines with non-zero error rates, so incorrectly classified examples will always be with us. And of course in the real world there are ambiguities in any data set, to the boundaries between classes are not as sharp as a labelled training set may make it seem.</p>

<p>Adversarial examples may be novel, but in the automated workplace workarounds have become routine, even if they are often overlooked. Automated systems shift decision-making from &ldquo;front line&rdquo; workers to a system, but as these systems have entered the workplace, many professionals have learned a new and often unacknowledged skill: they have become experts at making the system work properly.</p>

<p>As just one example, legal scholar Jennifer Raso explored the changing jobs of Ontario case workers when a new automated decision system was introduced. Instead of making their own judgements about client needs, case workers are now to enter data into the system, which would make a decision according to well-defined rules. She <a href="https://ssrn.com/abstract=3062620" target="_blank">writes about how the social service case workers responded</a>:</p>

<blockquote>
<p>While new technologies may attempt to deskill and decentre front-line decision-makers, transforming them into data entry clerks, caseworkers learn how to expertly translate and input client data to produce decisions that more closely match their interpretation of clients’ needs and welfare laws.</p>
</blockquote>

<p>The idea will be familiar to anyone who has read James C. Scott&rsquo;s <a href="https://yalebooks.yale.edu/book/9780300078152/seeing-state" target="_blank">Seeing Like a State</a>: certain schemes to improve the human condition assume, and impose, a simplified and idealized way of working and living that neglects the unruly irregularities of real life. Managed systems commonly rely on a certain level of workaround to even function: hence the effectiveness of the &ldquo;work to rule&rdquo; as a form of protest.</p>

<p>American healthcare systems have their own workarounds. The rigidities of automated billing systems recently produced a memorable essay by Atul Gawande entitled <a href="https://www.newyorker.com/magazine/2018/11/12/why-doctors-hate-their-computers" target="_blank">Why Doctors Hate Their Computers</a>, documenting many of the challenges experienced by physicians as new decision support systems have been introduced.</p>

<p>I said that adversarial attacks and workarounds are opposites, but in another way they are very similar. Surprisingly there is no way to distinguish unambiguously between an adversarial attack and a workaround in real-world environments within machine learning theory. Attempts to define &ldquo;attacks&rdquo; refer to &ldquo;intent&rdquo;, but who is to say what that is? Many examples focus on cases where &ldquo;ground truth&rdquo; is unambiguous (a picture of a bus is &ldquo;obviously&rdquo; not a picture of a monkey). Examples that are clearly artificial and intentional are reflections of lab research, not of how systems will play out in the wild. Some machine learning practitioners have gone so far as to define &ldquo;attacks&rdquo; as any attempt by a subject to influence the outcome of a machine learning system, which makes an attacker of anyone who has put effort into writing their resume in the hopes of getting a job. But don&rsquo;t take all this from me: if you want to hear an expert opinion on this definition problem, see <a href="https://www.youtube.com/watch?v=sFhD6ABghf8" target="_blank">this talk by David Evans</a>.</p>

<p>When it comes down to it, both adversarial examples and workarounds are deliberate changes to inputs in order to generate desired outputs. Machine learning systems are statistical, and however accurate they may be over a large data set, statistics will not say whether any one individual answer is correct. For complex tasks such as medical diagnosis certified &ldquo;correct&rdquo; answers are often not available. And if the &ldquo;correct&rdquo; answer is not well-defined, who is to say whether an intentional change is correcting a mistake or corrupting a correct answer?</p>

<p>Will workarounds be needed for the next generation of deep learning medical systems? We can&rsquo;t say for sure yet, but history suggests that they will. There is a long history of technical innovations that are designed around idealized and simplified models of behaviour, and which underestimate the complexities of &ldquo;edge cases&rdquo; in real life. Witness the over-enthusiasm around self-driving cars a couple of years ago, that is now being confronted with the messiness of reality.</p>

<p>The article is not completely silent on the topic of workaroudns: it does reference a paper from almost 20 years ago titled &ldquo;<a href="https://jamanetwork.com/journals/jama/fullarticle/192577" target="_blank">Physician Manipulation of Reimbursement Rules for Patients: Between a Rock and a Hard Place</a>&rdquo;, which says this:</p>

<blockquote>
<p>It has been suggested that some insurers are &ldquo;gaming&rdquo; patients and physicians&mdash;tricking them into paying for covered services by routinely denying coverage but then approving services that are subsequently appealed, knowing that time and other constraints will prevent some appeals.</p>
</blockquote>

<p>So doctor workarounds may be responses not only to technical deficiencies in the system, but also to real or perceived bad faith on the part of the insurers (or their suppliers) who are responsible for the system itself. And why should doctors have faith in these systems? Big money is at work on both sides, and the incentives for insurance companies to &ldquo;optimize&rdquo; is at least as strong as for the doctors. They face incentives to fix inaccuracies that lead to overbilling, but not those blind spots that lead to underpayments; to label edge cases in training sets in such a way as to minimize payments; to redefine payment schedules around the observed behaviour of the systems.</p>

<p>When it comes to interventions, Finlayson et al make two recommendations. The first is to procrastinate: to avoid stifling innovation by prematurely enforcing demands for robustness. The second is to increase supervision of medical practitioners, to check that they do not &ldquo;tamper&rdquo; with the data. Such an approach not only neglects any consideration of insurance companies, but it also rules out workarounds. It removes any room for doctors&rsquo; discretion and judgement, and reduces the role of physician to that of a managed and supervised data entry technician.</p>

<p>As I&rsquo;ve <a href="https://ssrn.com/abstract=3363342" target="_blank">written elsewhere</a>, most machine learning systems of any interest are <em>incentive incompatible.</em> The subjects who provide the inputs and the consumers of the outputs have different and conflicting interests. And in such an arrangement additional rules are not just likely, but inevitable. The problem with procrastination is that it favours the consumers and, more than anyone, the providers of the system. A natural response to problems is to demand more complete data, better data, and closer supervision of data entry. Without a check on insurance companies, medical machine learning systems will not be a cure for a damaged health system.</p>
</div>

    


    








  





  
  
  
    
  
  
  <div class="media author-card" itemscope itemtype="http://schema.org/Person">
    
      
      <img class="portrait mr-3" src="/authors/admin/avatar_hub378f18ec57be63e91148374089d19f9_9524045_250x250_fill_q90_lanczos_center.jpg" itemprop="image" alt="Avatar">
    

    <div class="media-body">
      <h5 class="card-title" itemprop="name"><a href="https://tomslee.github.io/"></a></h5>
      
      <p class="card-text" itemprop="description">Mainly technology and politics</p>
      <ul class="network-icon" aria-hidden="true">
        
          
          
          
            
          
          
          
          
          
            
          
          <li>
            <a itemprop="sameAs" href="/#contact" >
              <i class="fas fa-envelope"></i>
            </a>
          </li>
        
          
          
          
            
          
          
          
          
          
            
          
          <li>
            <a itemprop="sameAs" href="https://twitter.com/whimsley" target="_blank" rel="noopener">
              <i class="fab fa-twitter"></i>
            </a>
          </li>
        
          
          
          
          
          
          
          
            
          
          <li>
            <a itemprop="sameAs" href="https://scholar.google.co.uk/citations?hl=en&amp;user=-QdBcPCiO1sJ" target="_blank" rel="noopener">
              <i class="ai ai-google-scholar"></i>
            </a>
          </li>
        
          
          
          
            
          
          
          
          
          
            
          
          <li>
            <a itemprop="sameAs" href="https://github.com/tomslee" target="_blank" rel="noopener">
              <i class="fab fa-github"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>




  </div>
</div>


<div class="article-container article-widget">
  
<div class="post-nav">
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Next</div>
    <a href="/publication/workaround-medical/" rel="next">Workarounds in decision support systems</a>
  </div>
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Previous</div>
    <a href="/publication/rise_and_fall/" rel="prev">The Rise and Fall of the Sharing Economy</a>
  </div>
  
</div>

</div>


      

    
    
    
    <script src="/js/mathjax-config.js"></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js" integrity="sha256-aYTdUrn6Ow1DDgh5JTc3aDGnnju48y/1c8s1dgkYPQ8=" crossorigin="anonymous"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    
    
      <script async defer src="//maps.googleapis.com/maps/api/js?key=AIzaSyBrCa_lLBoxGFUhQMUn2gpb8H5_cioqe74"></script>
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/gmaps.js/0.4.25/gmaps.min.js" integrity="sha256-7vjlAeb8OaTrCXZkCNun9djzuB2owUsaO72kXaFDBJs=" crossorigin="anonymous"></script>
      
    

    
    
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.9ef1b53ee2bde6c7f33b150c6ba4d452.js"></script>

    






  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    Copyright &copy; 2006&ndash;2019 &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
